%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}
\IEEEoverridecommandlockouts
\overrideIEEEmargins
\input{preamble.tex}



\begin{document}
\title{Learning Efficient Strategies in Resource Utilization with Degradation}
\author{Bryce L. Ferguson and Rohit Konda}

\maketitle
\thispagestyle{empty}

% Specific Applications just problem properties
% Generalize Problem Setting
% State consequences in many other engineering settings
% Outline key questions and interesting ideas
% Hint at tools and innovations that we can use to answer the question

The effective utilization of our available resources can greatly improve operational performance in many settings. Often, as a resource is increasingly utilized, its current operating effectiveness is degraded. For example, rider-sharing platforms have become ubiquitous, and thus operating these platforms in an efficient manner is vital for rider satisfaction and minimizing usage costs. Thus, we propose to look to derive efficient planning algorithms for ride-sharing from the following perspective. First, consider when drivers are traveling across areas of an urban landscape. When drivers enter a specific area, we assume that some riders are serviced, and the number of un-serviced riders decreases. However, in areas that are not visited by drivers, the number of un-serviced riders may potentially increase. In this way, the goal of the network of drivers, as a whole, is to plan their routes effectively across the landscape, where the total number of unserviced riders would like to be kept a minimum. Effective planning algorithms are predicted to effectively coordinate drivers to areas with a high number of un-serviced riders as opposed to areas with less.

With this in mind, we propose the study of dynamic resource allocation problems in which a resources value degrades as it is utilized. In general, we would like to study problems of optimal resource extraction where resource utilization leads to resource degradation. In our models, we take inspiration from \emph{fishery games} that were studied in the economics literature in the 1980's, where the emphasis  was on protecting a common good from a social policy perspective. In our work, we take an novel outlook on this model, which is indicative of many different engineering application domains. Our innovation is that we can use tools from control theory and reinforcement learning to address these problems which are fundamental and natural problems to consider in a engineering realms.

Lets consider a set of resources that agents can use. These can be common goods, or private to agents. Agents can utilize these resources at a time, and can derive benefit from accessing these resources. However, utilizing these resources can affect the availability and quantity of the resource in the future. In this sense, greedy utilization in the short term by agents can lead to scarcity in the long-term. Thus, agents must consider a natural trade-off, in which they must balance short and long-term gains when utilizing resources. We would like to examine the strategies that agents must do so in a wide variety of instances.

For example, a battery management system may have access to several power storage devices, such as the proposed ideas of vehicle-to-grid charging where EV batteries can be used to store and supply power to a local grid. As a battery is used, its charge is depleted making it less valuable as a power source; further, in the case of the vehicle-to-grid charging scheme, it becomes less valuable as a car power supply. We can also model security problems in this framework.  Additionally, we can examine problems of dynamic server queing, natural resource harvesting, and task assignment from this framework.

These examples both highlight the fact that resource allocation/utilization is a dynamic process and effectively utilizing resources means adaptively changing how resources are allocated. Deriving algorithms which optimally utilize degradable resources will prove valuable in improving the operation of complex systems

In this pursuit, several important  and interesting questions emerge:

\noindent\textit{How do we optimally utilize resources which are affected by our actions?} If we take degrade a resource as we use it, but it returns as we stop using it, how do we optimize the long run performance of this

\noindent\textit{What impact does decentralized decision making have on the system?} If resources are shared among many users, perhaps in an environmental setting or in a ride sharing app, how do the selfish decisions of users affect the performance

\noindent\textit{How does uncertainty in a resources future value affect design and performance?} If we do not know how a resource will degrade (higher probability of error with higher loads), then how can we optimize and learn?

\noindent\textit{How do restrictions on agent decisions impact resource utilitization?} If we have restrictions (e.g.,  drivers assigned to different areas or team members or servers or any mis-match), then how do we optimize?

The way that we solve these question is through reinforcement learning and control theory.

\begin{figure}
    \centering
    \includegraphics[width=0.8\columnwidth]{EV.png}
    \caption{An example of EV charging. Subject to change.}
    \label{fig:app}
\end{figure}


\end{document}